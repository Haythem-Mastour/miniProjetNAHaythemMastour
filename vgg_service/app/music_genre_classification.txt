import librosa
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.models import Model

# Load the pre-trained VGG16 model without the top (fully connected) layers
vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Flatten the output of VGG16 and add dense layers for classification
x = vgg16_model.output
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
predictions = Dense(len(genre_dict), activation='softmax')(x)

# Create a new model with VGG16 as the base and the added dense layers
model = Model(inputs=vgg16_model.input, outputs=predictions)

# Load the weights of your pre-trained SVM model
model.load_weights('./svm-classification-model.h5')

def extract_features(file_path):
    # Load audio file with librosa
    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')
    # Convert audio to spectrogram (image)
    spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate)
    spec = librosa.power_to_db(spec, ref=np.max)

    # Resize the spectrogram to match VGG16 input shape (224x224)
    spec = cv2.resize(spec, (224, 224), interpolation=cv2.INTER_CUBIC)
    spec = np.stack((spec, spec, spec), axis=-1)  # Convert to 3-channel image

    # Preprocess the input for VGG16
    spec = preprocess_input(spec)

    return spec

# Rest of the code remains the same...

# Usage example
file_path = '/content/drive/MyDrive/data_docker/Data/genres_original/rock/rock.00096.wav'
genre = predict_genre(file_path)
print("Predicted Genre:", genre)
